# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11KJhH2k9gLqMMSUpO9BMmbnNDCQVXq3T

Transcribing Manuscripts

Preprosessing
"""

from google.colab import drive
drive.mount('/content/drive')

#imported stuff
import pandas as pd
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import tempfile
import cv2
import numpy as np
from PIL import Image
import zipfile
import os
import shutil
from IPython.display import display

file_path= "/content/Lewis E 172 (2).zip"
extract_path = "extracted_images"
processed_path = "processed_images"

IMAGE_SIZE = 1800
BINARY_THREHOLD = 180

#resize the image
def set_image_dpi(file_path):
    im = Image.open(file_path)
    #display(im)
    if im.mode == 'RGBA':
      im = im.convert('RGB')
    length_x, width_y = im.size
    factor = max(1, int(IMAGE_SIZE / length_x))
    size = factor * length_x, factor * width_y
    im_resized = im.resize(size, Image.Resampling.LANCZOS)
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
    temp_filename = temp_file.name
    im_resized.save(temp_filename, dpi=(300, 300))
    return temp_filename

#changes page to black and white
def image_smoothening(img):
    ret1, th1 = cv2.threshold(img, BINARY_THREHOLD, 255, cv2.THRESH_BINARY)
    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    blur = cv2.GaussianBlur(th2, (1, 1), 0)
    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return th3

#remove the patches of high intensity, smooth out the page
def remove_noise_and_smooth(file_name):
    img = cv2.imread(file_name, 0)
    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41, 3)
    kernel = np.ones((1, 1), np.uint8)
    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)
    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)
    img = image_smoothening(img)
    or_image = cv2.bitwise_or(img, closing)
    return or_image

#preprocess data
def process_image_for_ocr(file_path):
    temp_filename = set_image_dpi(file_path)
    im_new = remove_noise_and_smooth(temp_filename)
    return im_new

with zipfile.ZipFile(file_path, "r") as zip_ref:
  os.makedirs(extract_path, exist_ok=True)
  os.makedirs(processed_path, exist_ok=True)
  zip_ref.extractall(extract_path)
  extracted_files = os.listdir(extract_path)
  for root, dirs, files in os.walk(extract_path):
    for file_name in files:
      if file_name.endswith(".jpg"):
        full_file_name = os.path.join(root, file_name)
        try:
          processed= process_image_for_ocr(full_file_name)
          processed_pil = Image.fromarray(processed)
          processed_pil.save( processed_path + "/" + file_name + "output.jpg", format="JPEG")
        except Exception as e:
          #print(f"Error processing {file_name}: {e}")
          continue

"""Tessseract Model"""

# Install Tesseract and necessary dependencies
!sudo apt update
!sudo apt install tesseract-ocr
!sudo apt install tesseract-ocr-eng
!sudo apt install libtesseract-dev

# Verify installation
!tesseract --version

!pip install pytesseract Pillow

#from PIL import Image
import pytesseract
import os
"""
# Define the image path (assuming your image is in your Google Drive)
# Replace 'path/to/your/image.jpg' with the actual path to your image file in Google Drive
image_path = processed#'/content/testpage.jpg' # Replace with your actual path

# Check if the image file exists
if not os.path.exists(image_path):
    print(f"Error: Image file not found at {image_path}")
else:
    try:
        # Open the image file
        img = Image.open(image_path)

        # Perform OCR
        text = pytesseract.image_to_string(img)

        # Print the extracted text
        print(text)

    except Exception as e:
        print(f"An error occurred during OCR: {e}")
"""

for root, dirs, files in os.walk(processed_path):
  for file_name in files:
    full_file_name = os.path.join(root, file_name)
    img = Image.open(full_file_name)
    display(img)
    text = pytesseract.image_to_string(img)
    print(text)

"""Tesseract"""

# @title version 1 libraries
!apt-get update -qq
!apt-get install -y tesseract-ocr >/dev/null

# Grab the Latin model (you can switch tessdata_best -> tessdata_fast if you want it faster)
!wget -q https://github.com/tesseract-ocr/tessdata_best/raw/main/lat.traineddata -O /usr/share/tesseract-ocr/4.00/tessdata/lat.traineddata

def tesseract_model(img):
  # @title version 1
  import os
  import cv2
  import pytesseract
  from google.colab import files
  import numpy as np

  if isinstance(img, Image.Image):
        img = np.array(img)
  img = img.astype(np.uint8)

  # Make sure Tesseract knows where tessdata lives
  os.environ['TESSDATA_PREFIX'] = '/usr/share/tesseract-ocr/4.00/tessdata'
  pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'

  # Sanity check: do we see 'lat'?
  print("Available langs:", pytesseract.get_languages(config=''))
  """
  # Upload your image
  uploaded = files.upload()
  image_path = next(iter(uploaded))
  """
  # --- minimal preprocessing ---
  #img = cv2.imread(image_path)
  #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  #gray = cv2.medianBlur(gray, 3)
  #_, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

  #custom_config = r'--oem 3 --psm 6 -l lat'
  #text = pytesseract.image_to_string(thresh, config=custom_config)

  #print("=== OCR Output ===\n")
  #print(text)
  gray = img.copy()
  gray = cv2.medianBlur(gray, 3)
  _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

  custom_config = r'--oem 3 --psm 6 -l lat'
  text = pytesseract.image_to_string(thresh, config=custom_config)

  print("=== OCR Output ===\n")
  print(text)
  return text

for root, dirs, files in os.walk(processed_path):
  for file_name in files:
    full_file_name = os.path.join(root, file_name)
    img = Image.open(full_file_name)
    display(img)
    #text = pytesseract.image_to_string(img)
    #print(text)
    tesseract_model(img)